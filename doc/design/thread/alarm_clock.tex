
\section{ALARM CLOCK}

\begin{aspect}{DATA STRUCTURES}
	\begin{qc}
		A1: Copy here the declaration of each new or changed `struct' or
		`struct' member, global or static variable, `typedef', or
		enumeration.  Identify the purpose of each in 25 words or less.
	\end{qc}
	Add a list to store the sleeping threads.
	\begin{lstlisting}
/* List of sleep threads and its lock*/
static struct list sleep_list;
  \end{lstlisting}
	Add to \lstinline{struct thread} in \lstinline{threads/thread.h}
	\begin{lstlisting}
/* Owned by timer.c */
struct list_elem sleepelem; /* List element for sleep thread queue*/
int64_t sleep_to;           /* sleep until `sleep_tp` ticks */
  \end{lstlisting}
\end{aspect}
\begin{aspect}{ALGORITHMS}
	\begin{qc}
		A2: Briefly describe what happens in a call to \lstinline{timer_sleep()}, including the effects of the timer interrupt handler.
	\end{qc}
	When calling \lstinline{timer_sleep()}, we first calculate until when (in ticks) the thread needs to sleep. Then we insert the thread into \lstinline{sleep_list} and block the thread.

	The timer interrupt handler will check the \lstinline{sleep_list} to find all the threads need to be awaken. It will unblock those threads and remove them from the list.

	\begin{qc}
		A3: What steps are taken to minimize the amount of time spent in the timer interrupt handler?
	\end{qc}

	First, when inserting thread into \lstinline{sleep_list}, we ensure that the threads in the list are sorted in ascending order by their \lstinline{sleep_to} fields.

	Then the timer interrupt only need to check the first few threads until it found the first thread which still needs sleeo. This only costs constant time.
\end{aspect}

\begin{aspect}{SYNCRONIZATION}
	\begin{qc}
		A4: How are race conditions avoided when multiple threads call \lstinline{timer_sleep()} simultaneously?
	\end{qc}
	When we call \lstinline{timer_sleep()}, we disable the interrupt before we access to the \lstinline{sleep_list}, and we won't enable the inrerrupt until we block this thread. Since Pintos is designed for single core processor without hyper threading, even if multiple threads call \lstinline{timer_sleep()} simultaneously, only one of them can be run at the same time. We only have to ensure that when a thread is operating the \lstinline{sleep_list}, it is not interrupted or switched. When external interrupt is disabled the interrupt, if one thread starts operation, other threads will not be able to interrupt that thread. Other thread must wait for the operation completes. Therfore, race condition is eliminated.
	\begin{qc}
		A5: How are race conditions avoided when a timer interrupt occurs during a call to \lstinline{timer_sleep()}?
	\end{qc}
	When a thread acquires the \lstinline{timer_sleep_lock}, it will disable interrupt immediately and will not allow interrupt until the thread is blocked. Therfore, there will not be any race condition.
\end{aspect}

\begin{aspect}{RATIONALE}
	\begin{qc}
		A6: Why did you choose this design?  In what ways is it superior to another design you considered?
	\end{qc}
	At first, I consider to use another thread to monitor all the sleep thread. Each time this thread runs, it will wake up all the other threads which should not be sleeping any more. However, this approach needs to initialize a thread immediately after the os was booted. This may be inefficient. In logic, letting timer owns a standalone thread to monitor other thread is not reasonable. What's more, it is uncertain when the monitor thread will be run, so the sleep time for each thread may be inaccurate.

	To address this problem, I try to leveraging \lstinline{timer_interrupt ()} and come up with three designs.
	\begin{itemize}
		\item In \lstinline{timer_interrupt ()}, go through all threads \lstinline{all_list} to check if some threads can be awaken.
		\item My current design: maintain a linked list of sleeping threads, sort by \lstinline{sleep_to} on insertion. Wake up a thread in \lstinline{timer_interrupt ()}.
		\item Similar to the previous one, but use a binary heap instead of a linked list to add and remove sleeping threads efficiently.
	\end{itemize}

    Among them: the first one is quite inefficient algorithm simple to implement.
    The last one is the fastest one in the sense of asymptotic complexity.
    However the implementation is quite complicated.
    Also, I noticed that when running pintos, only a few threads are sleeping at the same time.
    A binary heap won't have a sensible performance advantage over a linked list when maintaining a small amount of elements.

	Therefore, I decided to use the second design for its balance between simplicity and efficiency.
\end{aspect}
